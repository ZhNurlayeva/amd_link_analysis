{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZhNurlayeva/amd_link_analysis/blob/main/amd_link_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP9T1T-71xxy"
      },
      "source": [
        "### Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy3pUXMi88sX"
      },
      "source": [
        "### 0.1 Install required packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYcWe64i5T5f"
      },
      "source": [
        "Install external libraries for title normalisation, MinHash/LSH, and sentence-based similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jiGMW7SE5OQD"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle datasketch -q\n",
        "!pip install sentence-transformers jellyfish python-Levenshtein faiss-cpu -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-36oGgA5gfO"
      },
      "source": [
        "### 0.2 Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR7D7DPzkdkd"
      },
      "source": [
        "Core scientific stack, graph tools, similarity functions, and MinHash/LSH."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gRMtD4T85lEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32b5c49-cbae-4f34-e45f-ccb72c8f3230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "# Core Python and scientific stack\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import gc\n",
        "import unicodedata\n",
        "from collections import defaultdict, Counter, deque\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "# String similarity and semantic models for title normalisation\n",
        "import jellyfish\n",
        "import Levenshtein\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# MinHash and LSH for scalable similarity search\n",
        "from datasketch import MinHash, MinHashLSH\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iU2MIsI79ApL"
      },
      "source": [
        "### 0.3 Kaggle API configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOlrMrh56Vd7"
      },
      "source": [
        "Upload kaggle.json and configure the Kaggle API for programmatic dataset download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HZXOEMxeUdE",
        "outputId": "88b9c94b-c565-4bc4-d0f5-7abaa7bbcc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle API authenticated.\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import files\n",
        "#from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "#uploaded = files.upload()  # upload kaggle.json\n",
        "\n",
        "#!mkdir -p /root/.config/kaggle\n",
        "#!cp kaggle.json /root/.config/kaggle/kaggle.json\n",
        "#!chmod 600 /root/.config/kaggle/kaggle.json\n",
        "\n",
        "#api = KaggleApi()\n",
        "#api.authenticate()\n",
        "import os\n",
        "\n",
        "KAGGLE_DIR = \"/root/.config/kaggle\"\n",
        "KAGGLE_PATH = f\"{KAGGLE_DIR}/kaggle.json\"\n",
        "\n",
        "# 1) Ensure kaggle.json exists (upload only if missing)\n",
        "if not os.path.exists(KAGGLE_PATH):\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()  # upload kaggle.json\n",
        "\n",
        "    os.makedirs(KAGGLE_DIR, exist_ok=True)\n",
        "    !cp kaggle.json /root/.config/kaggle/kaggle.json\n",
        "    !chmod 600 /root/.config/kaggle/kaggle.json\n",
        "\n",
        "# 2) Now import and authenticate\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "print(\"Kaggle API authenticated.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKGVtfIZ6jp-"
      },
      "source": [
        "### 1. Data acquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9_djKL46n6I"
      },
      "source": [
        "Download the Amazon Books Reviews dataset from Kaggle and load the two source files:\n",
        "\n",
        "* the main ratings table containing user–book interactions, and\n",
        "* the metadata table containing book-level attributes.  \n",
        "\n",
        "These raw tables form the starting point for all later cleaning, filtering, and graph construction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "APri4iSd6xoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204c708b-bfef-493c-d498-c79d7ee9514f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "Downloading amazon-books-reviews.zip to .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.06G/1.06G [00:21<00:00, 52.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ratings shape: (3000000, 10)\n",
            "Metadata shape: (212404, 10)\n",
            "Ratings columns: ['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness', 'review/score', 'review/time', 'review/summary', 'review/text']\n",
            "Metadata columns: ['Title', 'description', 'authors', 'image', 'previewLink', 'publisher', 'publishedDate', 'infoLink', 'categories', 'ratingsCount']\n"
          ]
        }
      ],
      "source": [
        "DATASET_NAME = \"mohamedbakhet/amazon-books-reviews\"\n",
        "\n",
        "api.dataset_download_files(\n",
        "    dataset=DATASET_NAME,\n",
        "    path=\".\",\n",
        "    unzip=True,\n",
        "    quiet=False\n",
        ")\n",
        "\n",
        "RATINGS_PATH = \"Books_rating.csv\"\n",
        "BOOKS_META_PATH = \"books_data.csv\"\n",
        "\n",
        "df_raw = pd.read_csv(RATINGS_PATH)\n",
        "df_meta = pd.read_csv(BOOKS_META_PATH)\n",
        "\n",
        "print(\"Ratings shape:\", df_raw.shape)\n",
        "print(\"Metadata shape:\", df_meta.shape)\n",
        "print(\"Ratings columns:\", list(df_raw.columns))\n",
        "print(\"Metadata columns:\", list(df_meta.columns))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21T0huY5k4lW"
      },
      "source": [
        "The ratings table contains 3M user–book interactions with review timestamps and scores, while the metadata file provides supplementary information such as categories, authors, and publication data. Both tables will be merged later, but at this stage the goal is to confirm their size and schema before preprocessing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcRhQVcPBBfr"
      },
      "source": [
        "### 2. Basic dataset inspection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be43BBo1B9Ft"
      },
      "source": [
        "Inspect the size, completeness, and sparsity of the raw ratings table before applying any cleaning steps. These diagnostics highlight missing identifiers and the long-tail distribution of user activity and book popularity, which will justify filtering thresholds used in later preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bTSkjKo98TLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b0f9f55-5014-423e-e7f2-196232dd4ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Basic dataset profile\n",
            "Total reviews          : 3,000,000\n",
            "Distinct book IDs      : 221,998\n",
            "Distinct raw titles    : 212,403\n",
            "Distinct users         : 1,008,972\n",
            "\n",
            "# Missing values in key fields\n",
            "Id                   0\n",
            "Title              208\n",
            "User_id         561787\n",
            "review/score         0\n",
            "dtype: int64\n",
            "\n",
            "# Sparsity indicators\n",
            "Reviews per title   – median=3.0, mean=14.1, max=22,023\n",
            "Reviews per user    – median=1.0, mean=2.4, max=5,795\n",
            "Users with 1–2 reviews : 83.1%\n",
            "Titles with <10 reviews: 79.3%\n"
          ]
        }
      ],
      "source": [
        "print(\"# Basic dataset profile\")\n",
        "\n",
        "total_reviews = len(df_raw)\n",
        "n_users       = df_raw[\"User_id\"].nunique()\n",
        "n_ids         = df_raw[\"Id\"].nunique()\n",
        "n_titles_raw  = df_raw[\"Title\"].nunique()\n",
        "\n",
        "print(f\"Total reviews          : {total_reviews:,}\")\n",
        "print(f\"Distinct book IDs      : {n_ids:,}\")\n",
        "print(f\"Distinct raw titles    : {n_titles_raw:,}\")\n",
        "print(f\"Distinct users         : {n_users:,}\")\n",
        "\n",
        "print(\"\\n# Missing values in key fields\")\n",
        "print(df_raw[[\"Id\", \"Title\", \"User_id\", \"review/score\"]].isna().sum())\n",
        "\n",
        "print(\"\\n# Sparsity indicators\")\n",
        "\n",
        "# Reviews per raw title\n",
        "book_review_counts = df_raw[\"Title\"].value_counts()\n",
        "print(\n",
        "    \"Reviews per title   – \"\n",
        "    f\"median={book_review_counts.median():.1f}, \"\n",
        "    f\"mean={book_review_counts.mean():.1f}, \"\n",
        "    f\"max={book_review_counts.max():,}\"\n",
        ")\n",
        "\n",
        "# Reviews per user (excluding missing user ids)\n",
        "valid_users_df = df_raw.dropna(subset=[\"User_id\"])\n",
        "user_review_counts = valid_users_df[\"User_id\"].value_counts()\n",
        "print(\n",
        "    \"Reviews per user    – \"\n",
        "    f\"median={user_review_counts.median():.1f}, \"\n",
        "    f\"mean={user_review_counts.mean():.1f}, \"\n",
        "    f\"max={user_review_counts.max():,}\"\n",
        ")\n",
        "\n",
        "# Share of very low-activity users and titles\n",
        "users_1_or_2  = (user_review_counts <= 2).mean() * 100\n",
        "books_less_10 = (book_review_counts < 10).mean() * 100\n",
        "print(f\"Users with 1–2 reviews : {users_1_or_2:4.1f}%\")\n",
        "print(f\"Titles with <10 reviews: {books_less_10:4.1f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7tRg2qCl6JM"
      },
      "source": [
        "The dataset is extremely sparse: most users have only one or two reviews, and most titles receive fewer than ten reviews. Such long-tail behaviour indicates that a large portion of the data cannot support meaningful overlap signals for graph construction. These statistics motivate the row-reduction step that follows, where both low-activity users and low-review titles are filtered out to obtain a denser and more reliable interaction core.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFPhWt_0-N-t"
      },
      "source": [
        "### 2.1 Merge category metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lchsj7mT-Sg2"
      },
      "source": [
        "Attach category labels from the metadata table to the raw ratings so that each title carries a genre/category attribute when available. These labels are not used for graph construction but will support downstream interpretation of central books and community structure.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VagnrRBT-PV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317abf7b-6d09-43cd-b4ec-287be3925dd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata merged. Distinct categories: 10884\n"
          ]
        }
      ],
      "source": [
        "df_meta_small = df_meta[[\"Title\", \"categories\"]].drop_duplicates()\n",
        "\n",
        "df_raw = df_raw.merge(\n",
        "    df_meta_small,\n",
        "    on=\"Title\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "print(\"Metadata merged. Distinct categories:\", df_raw[\"categories\"].nunique(dropna=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHVa1BN-mOrx"
      },
      "source": [
        "The merge succeeds for most titles, though the category field remains highly heterogeneous with many distinct labels. These categories will not affect preprocessing but will be aggregated later to characterise the genres of structurally central books.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1NQ28P19Ktc"
      },
      "source": [
        "### 3. Cleaning of interaction data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgyY2QSY9VC7"
      },
      "source": [
        "Construct a clean interaction table containing only the fields needed for graph construction. Missing identifiers are removed, category labels are normalised, and repeated (user, book) interactions are dropped. This step ensures that downstream row-reduction and title normalisation operate on a consistent and deduplicated dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-Ro4ReZl9K1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e117bf-192b-4f2b-f2ec-194d1595b8d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows removed due to missing Id/Title/User_id: 561,982\n",
            "Remaining rows after NA cleaning             : 2,438,018\n",
            "Duplicate (User_id, Id) pairs removed        : 40,599\n",
            "Unique (User_id, Id) interactions            : 2,397,419\n",
            "Distinct users after cleaning                : 1,008,961\n",
            "Distinct book IDs after cleaning             : 216,014\n",
            "Distinct raw titles after cleaning           : 206,711\n",
            "Distinct categories (incl. 'Unknown')        : 10,669\n"
          ]
        }
      ],
      "source": [
        "# Keep only fields used later in the pipeline\n",
        "df_clean = df_raw[[\"Id\", \"Title\", \"User_id\", \"review/score\", \"review/time\", \"categories\"]].copy()\n",
        "\n",
        "# Replace missing categories with a neutral label\n",
        "df_clean[\"categories\"] = df_clean[\"categories\"].fillna(\"Unknown\")\n",
        "\n",
        "# Remove rows with missing key identifiers\n",
        "before = len(df_clean)\n",
        "df_clean = df_clean.dropna(subset=[\"Id\", \"Title\", \"User_id\"])\n",
        "after = len(df_clean)\n",
        "print(f\"Rows removed due to missing Id/Title/User_id: {before - after:,}\")\n",
        "print(f\"Remaining rows after NA cleaning             : {after:,}\")\n",
        "\n",
        "# Remove duplicate interactions: same user reviewing the same book multiple times\n",
        "before = len(df_clean)\n",
        "df_clean = df_clean.drop_duplicates(subset=[\"User_id\", \"Id\"], keep=\"first\")\n",
        "after = len(df_clean)\n",
        "print(f\"Duplicate (User_id, Id) pairs removed        : {before - after:,}\")\n",
        "print(f\"Unique (User_id, Id) interactions            : {after:,}\")\n",
        "\n",
        "# Updated uniqueness counts\n",
        "print(f\"Distinct users after cleaning                : {df_clean['User_id'].nunique():,}\")\n",
        "print(f\"Distinct book IDs after cleaning             : {df_clean['Id'].nunique():,}\")\n",
        "print(f\"Distinct raw titles after cleaning           : {df_clean['Title'].nunique():,}\")\n",
        "print(f\"Distinct categories (incl. 'Unknown')        : {df_clean['categories'].nunique():,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrEcXYLMnVeR"
      },
      "source": [
        "The removal of missing identifiers and duplicate interactions reduces the dataset to a clean set of unique user–book pairs. The number of titles and users remains high, but the interactions become more reliable for later analysis of reviewer overlap. Normalising missing categories ensures that all books carry a valid label for downstream genre-based interpretation of centrality and communities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FklL1Vn_s32"
      },
      "source": [
        "###4. Row reduction (core extraction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr-2hOQ6_xtZ"
      },
      "source": [
        "This step filters the cleaned interaction table `df_clean` down to an active core `df_core_raw`.\n",
        "Based on the distributions `book_counts_all` and `user_counts_all` (showing that ~80% of titles have fewer than 10 reviews and most users write only 1–2 reviews), it keeps only titles with at least `MIN_REVIEWS_PER_BOOK = 20` reviews and users with at least `MIN_REVIEWS_PER_USER = 3` reviews. This ensures that, when `df_core_raw` is later converted into reviewer sets (`book_users`) and edges between books are defined by ≥2 shared reviewers, the overlap signal is not dominated by almost-isolated titles or one-off users.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBlQlV4pAawy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b63af9-dd8f-43c2-db78-da40197e1068"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row reduction on cleaned interactions\n",
            "Books – reviews per (raw) title\n",
            "count    206711.000000\n",
            "mean         11.597927\n",
            "std          91.594057\n",
            "min           1.000000\n",
            "50%           2.000000\n",
            "75%           6.000000\n",
            "90%          18.000000\n",
            "99%         148.000000\n",
            "max       17392.000000\n",
            "Name: count, dtype: float64\n",
            "\n",
            "Users – reviews per user\n",
            "count    1.008961e+06\n",
            "mean     2.376127e+00\n",
            "std      1.121566e+01\n",
            "min      1.000000e+00\n",
            "50%      1.000000e+00\n",
            "75%      2.000000e+00\n",
            "90%      4.000000e+00\n",
            "99%      1.900000e+01\n",
            "max      5.534000e+03\n",
            "Name: count, dtype: float64\n",
            "\n",
            "Filtering titles with ≥ 20 reviews and users with ≥ 3 reviews...\n"
          ]
        }
      ],
      "source": [
        "print(\"Row reduction on cleaned interactions\")\n",
        "\n",
        "# Reviews per (raw) title and per user, after basic cleaning\n",
        "book_counts_all = df_clean[\"Title\"].value_counts()\n",
        "user_counts_all = df_clean[\"User_id\"].value_counts()\n",
        "\n",
        "print(\"Books – reviews per (raw) title\")\n",
        "print(book_counts_all.describe(percentiles=[0.5, 0.75, 0.9, 0.99]))\n",
        "\n",
        "print(\"\\nUsers – reviews per user\")\n",
        "print(user_counts_all.describe(percentiles=[0.5, 0.75, 0.9, 0.99]))\n",
        "\n",
        "# Thresholds for the interaction core\n",
        "MIN_REVIEWS_PER_BOOK = 20    # keep titles with at least 20 reviews\n",
        "MIN_REVIEWS_PER_USER = 3     # keep users who reviewed at least 3 books\n",
        "\n",
        "print(\n",
        "    f\"\\nFiltering titles with ≥ {MIN_REVIEWS_PER_BOOK} reviews \"\n",
        "    f\"and users with ≥ {MIN_REVIEWS_PER_USER} reviews...\"\n",
        ")\n",
        "\n",
        "# Select popular titles and active users\n",
        "popular_titles = book_counts_all[book_counts_all >= MIN_REVIEWS_PER_BOOK].index\n",
        "active_users   = user_counts_all[user_counts_all >= MIN_REVIEWS_PER_USER].index\n",
        "\n",
        "# Core interaction table (still with raw titles)\n",
        "df_core_raw = df_clean[\n",
        "    df_clean[\"Title\"].isin(popular_titles)\n",
        "    & df_clean[\"User_id\"].isin(active_users)\n",
        "].copy()\n",
        "\n",
        "print(f\"Rows after core filtering : {len(df_core_raw):,}\")\n",
        "print(f\"Distinct raw titles       : {df_core_raw['Title'].nunique():,}\")\n",
        "print(f\"Distinct users            : {df_core_raw['User_id'].nunique():,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVQp_7lYpoYl"
      },
      "source": [
        "The summary confirms that the raw interaction space is highly skewed: many titles and users sit in the extreme long tail, while a smaller subset carries most of the interaction mass.  \n",
        "After filtering, `df_core_raw` still contains over one million interactions, but now restricted to ~18k raw titles and ~157k active users, each with enough activity to participate in meaningful co-review overlaps.  \n",
        "This focused core strikes a balance between coverage and reliability and is the actual dataset on which title normalisation, reviewer-set construction, and the PageRank-based ranking will operate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvq_Jk0_A6KI"
      },
      "source": [
        "### 5. Canonical title normalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lzDho30Lzb"
      },
      "source": [
        "#### 5.1 Rule-based and semantic normalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkuO3vfsBA3T"
      },
      "source": [
        "The raw interaction core `df_core_raw` still contains many textual variants of the same book\n",
        "(e.g. different editions, formats, or small punctuation differences in the title).  \n",
        "If each variant were treated as a separate node, the co-review graph would fragment the same work across multiple titles,\n",
        "distorting degrees, reviewer overlaps, and ultimately PageRank.\n",
        "\n",
        "The `TitleCanonicalizer` class defines a normalisation pipeline that:\n",
        "- performs rule-based cleaning of the raw `Title` strings (removing format markers, brackets, punctuation),  \n",
        "- extracts a simplified “core” title,  \n",
        "- uses string similarity (Jaro–Winkler and Levenshtein) to cluster close variants, and  \n",
        "- refines the mapping on the most popular titles with a sentence-transformer model, merging semantically similar variants.\n",
        "\n",
        "The output is a dictionary `title_map_` that maps each raw `Title` in `df_core_raw` to a canonical representative, ensuring that each underlying work will correspond to a single node in the co-review graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdQa1M5fA6Uj"
      },
      "outputs": [],
      "source": [
        "class TitleCanonicalizer:\n",
        "\n",
        "    def __init__(self, use_semantic=True, max_semantic_titles=5000):\n",
        "        self.use_semantic = use_semantic\n",
        "        self.max_semantic_titles = max_semantic_titles\n",
        "        self._st_model = None\n",
        "        self.title_map_ = {}\n",
        "\n",
        "\n",
        "    # Basic text cleaning\n",
        "    def _clean_basic(self, title: str) -> str:\n",
        "        if pd.isna(title):\n",
        "            return \"\"\n",
        "\n",
        "        t = str(title).lower().strip()\n",
        "        t = re.sub(r\"\\[.*?\\]\", \" \", t)\n",
        "        t = re.sub(r\"\\(.*?\\)\", \" \", t)\n",
        "\n",
        "        noise_patterns = [\n",
        "            r\"\\bpaperback\\b\",\n",
        "            r\"\\bhardcover\\b\",\n",
        "            r\"\\bkindle\\b\",\n",
        "            r\"\\baudio\\s*book\\b\",\n",
        "            r\"\\baudiobook\\b\",\n",
        "            r\"\\bcd\\b\",\n",
        "            r\"\\bdvd\\b\",\n",
        "            r\"\\bedition\\b\",\n",
        "            r\"\\bvolume\\b\",\n",
        "            r\"\\bvol\\.\\b\",\n",
        "            r\"\\bclassics?\\b\",\n",
        "            r\"\\billustrated\\b\",\n",
        "        ]\n",
        "        for pat in noise_patterns:\n",
        "            t = re.sub(pat, \" \", t)\n",
        "\n",
        "        t = re.sub(r\"[^a-z0-9\\s]\", \" \", t)\n",
        "        return \" \".join(t.split())\n",
        "\n",
        "\n",
        "    # Extract core title\n",
        "    def _core_title(self, title: str) -> str:\n",
        "        if pd.isna(title):\n",
        "            return \"\"\n",
        "\n",
        "        t = str(title).lower()\n",
        "\n",
        "        m = re.match(r\"^([^:;]+)\", t)\n",
        "        if m:\n",
        "            t = m.group(1)\n",
        "\n",
        "        t = re.sub(r\"\\bby\\s+[a-z\\s\\.]+$\", \" \", t)\n",
        "        t = re.sub(r\"\\([^)]*\\)\", \" \", t)\n",
        "        t = re.sub(r\"[^a-z0-9\\s]\", \" \", t)\n",
        "        return \" \".join(t.split())\n",
        "\n",
        "    # String similarity\n",
        "    def _string_similarity(self, t1: str, t2: str) -> float:\n",
        "        if not t1 or not t2:\n",
        "            return 0.0\n",
        "\n",
        "        b1 = self._clean_basic(t1)\n",
        "        b2 = self._clean_basic(t2)\n",
        "        c1 = self._core_title(t1)\n",
        "        c2 = self._core_title(t2)\n",
        "\n",
        "        sims = []\n",
        "        if b1 and b2:\n",
        "            sims.append(jellyfish.jaro_winkler_similarity(b1, b2))\n",
        "            sims.append(Levenshtein.ratio(b1, b2))\n",
        "        if c1 and c2:\n",
        "            sims.append(jellyfish.jaro_winkler_similarity(c1, c2))\n",
        "            sims.append(Levenshtein.ratio(c1, c2))\n",
        "\n",
        "        return max(sims) if sims else 0.0\n",
        "\n",
        "\n",
        "    # Pick canonical title in a cluster\n",
        "    def _pick_canonical(self, variants, df):\n",
        "        scores = {}\n",
        "        for t in variants:\n",
        "            score = 0\n",
        "            score += df[df[\"Title\"] == t].shape[0] * 10   # popularity\n",
        "            score -= len(t) * 0.1                         # shorter is preferred\n",
        "            for marker in [\"audiobook\", \"kindle\", \"paperback\", \"hardcover\", \"edition\"]:\n",
        "                if marker in t.lower():\n",
        "                    score -= 50\n",
        "            score -= len(re.findall(r\"[^\\w\\s]\", t)) * 5   # punctuation penalty\n",
        "            scores[t] = score\n",
        "\n",
        "        return max(scores.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "\n",
        "    # Popularity-aware semantic refinement\n",
        "    def _semantic_refinement(self, canonical_titles, df, sim_threshold=0.85):\n",
        "\n",
        "        if not self.use_semantic or len(canonical_titles) <= 1:\n",
        "            return {}\n",
        "\n",
        "        title_counts = df[\"Title\"].value_counts()\n",
        "\n",
        "        popular_order = (\n",
        "            pd.Series(list(canonical_titles), name=\"Title\")\n",
        "            .drop_duplicates()\n",
        "            .to_frame()\n",
        "            .join(title_counts.rename(\"count\"), on=\"Title\")\n",
        "            .fillna(0)\n",
        "            .sort_values(\"count\", ascending=False)\n",
        "        )\n",
        "\n",
        "        popular_titles = popular_order[\"Title\"].tolist()\n",
        "        titles_sub = popular_titles[: self.max_semantic_titles]\n",
        "\n",
        "        if len(popular_titles) > self.max_semantic_titles:\n",
        "            print(f\"  Semantic refinement on top {self.max_semantic_titles} most-reviewed titles\")\n",
        "        else:\n",
        "            print(f\"  Semantic refinement on all {len(popular_titles)} canonical titles\")\n",
        "\n",
        "        if len(titles_sub) <= 1:\n",
        "            return {}\n",
        "\n",
        "        print(\"  Encoding titles with sentence-transformers...\")\n",
        "        if self._st_model is None:\n",
        "            self._st_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "        emb = self._st_model.encode(\n",
        "            titles_sub,\n",
        "            show_progress_bar=True,\n",
        "            normalize_embeddings=True\n",
        "        )\n",
        "\n",
        "        sim_mat = np.dot(emb, emb.T)\n",
        "\n",
        "        used = set()\n",
        "        clusters = []\n",
        "        for i in range(len(titles_sub)):\n",
        "            if i in used:\n",
        "                continue\n",
        "            close_idx = np.where(sim_mat[i] >= sim_threshold)[0]\n",
        "            group = [titles_sub[j] for j in close_idx]\n",
        "            if len(group) > 1:\n",
        "                clusters.append(group)\n",
        "            used.update(close_idx)\n",
        "\n",
        "        semantic_map = {}\n",
        "        for group in clusters:\n",
        "            canon = self._pick_canonical(group, df)\n",
        "            for t in group:\n",
        "                semantic_map[t] = canon\n",
        "\n",
        "        return semantic_map\n",
        "\n",
        "\n",
        "    # Main method\n",
        "    def fit(self, df, sim_threshold=0.85):\n",
        "\n",
        "        print(\"Advanced title normalization\")\n",
        "        all_titles = df[\"Title\"].dropna().unique()\n",
        "        print(f\"Raw unique titles: {len(all_titles):,}\")\n",
        "\n",
        "        grouped = defaultdict(list)\n",
        "        for t in all_titles:\n",
        "            key = self._clean_basic(t)\n",
        "            if key:\n",
        "                grouped[key].append(t)\n",
        "\n",
        "        base_map = {}\n",
        "        canonical_list = []\n",
        "\n",
        "        for key, group in grouped.items():\n",
        "            if len(group) == 1:\n",
        "                base_map[group[0]] = group[0]\n",
        "                canonical_list.append(group[0])\n",
        "            else:\n",
        "                canon = self._pick_canonical(group, df)\n",
        "                for t in group:\n",
        "                    base_map[t] = canon\n",
        "                canonical_list.append(canon)\n",
        "\n",
        "        extra_map = self._semantic_refinement(canonical_list, df, sim_threshold=sim_threshold)\n",
        "\n",
        "        final_map = {}\n",
        "        for orig, canon in base_map.items():\n",
        "            final_map[orig] = extra_map.get(canon, canon)\n",
        "\n",
        "        self.title_map_ = final_map\n",
        "        merged = sum(1 for k, v in final_map.items() if k != v)\n",
        "        print(f\"Titles merged into canonical forms: {merged:,}\")\n",
        "\n",
        "        return self.title_map_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLNwcD5lBUOr"
      },
      "source": [
        "### 5.2 Apply canonical mapping to the interaction core"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUIB8nocBeeW"
      },
      "source": [
        "The normalisation is applied only to the reduced interaction core `df_core_raw`  \n",
        "(≈18k raw titles after row reduction) to keep runtime manageable while still covering all high-activity books.  \n",
        "The fitted `TitleCanonicalizer` produces `title_map_core`, which is used to build:\n",
        "\n",
        "- a canonical interaction table `df_core`, with both `Title_original` and `Title_canon`, and  \n",
        "- an aggregated category label `category_final` for each canonical title, obtained by majority vote over `categories`.\n",
        "\n",
        "After this step, each canonical title in `df_core` will be used as a unique node when constructing reviewer sets and the co-review graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P0pk0O6BUXu"
      },
      "outputs": [],
      "source": [
        "normalizer = TitleCanonicalizer(use_semantic=True, max_semantic_titles=5000)\n",
        "\n",
        "start = time.time()\n",
        "title_map_core = normalizer.fit(df_core_raw, sim_threshold=0.85)\n",
        "end = time.time()\n",
        "print(f\"\\nCore deduplication (with semantic refinement) completed in {end - start:.1f} seconds\")\n",
        "\n",
        "# Construct canonical interaction table\n",
        "df_core = df_core_raw.copy()\n",
        "df_core[\"Title_original\"] = df_core[\"Title\"]\n",
        "df_core[\"Title_canon\"] = df_core[\"Title\"].map(lambda t: title_map_core.get(t, t))\n",
        "\n",
        "# Aggregate categories at canonical-title level (majority label)\n",
        "cat_counts_core = (\n",
        "    df_core.groupby([\"Title_canon\", \"categories\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"n\")\n",
        ")\n",
        "\n",
        "top_category_core = (\n",
        "    cat_counts_core.sort_values([\"Title_canon\", \"n\"], ascending=[True, False])\n",
        "    .drop_duplicates(subset=[\"Title_canon\"])\n",
        "    .set_index(\"Title_canon\")[\"categories\"]\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "df_core[\"category_final\"] = df_core[\"Title_canon\"].map(top_category_core)\n",
        "\n",
        "print(\"\\nCore deduplication summary\")\n",
        "print(f\"Unique raw titles in core       : {df_core_raw['Title'].nunique():,}\")\n",
        "print(f\"Unique canonical titles in core : {df_core['Title_canon'].nunique():,}\")\n",
        "\n",
        "# Remove duplicate (User_id, Title_canon) pairs created by merging\n",
        "before = len(df_core)\n",
        "df_core = df_core.drop_duplicates(subset=[\"User_id\", \"Title_canon\"], keep=\"first\")\n",
        "after = len(df_core)\n",
        "print(\n",
        "    f\"Final canonical core for link analysis: {after:,} reviews \"\n",
        "    f\"(removed {before - after:,} duplicate user–title pairs)\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF1gWCLSuIXn"
      },
      "source": [
        "The normalisation step starts from 18,421 raw titles in `df_core_raw` and merges 2,239 of them into canonical forms,\n",
        "resulting in 16,182 distinct `Title_canon` entries.  \n",
        "This shows that a non-trivial fraction of the interaction core was affected by edition/format variants or minor textual differences.\n",
        "\n",
        "After applying `title_map_core` and dropping duplicate `(User_id, Title_canon)` pairs, the final canonical core contains 596,700 reviews.\n",
        "Each canonical title now aggregates all reviews that previously belonged to its fragmented variants, and each `(user, book)` interaction appears at most once.\n",
        "\n",
        "This cleaned table `df_core` is the basis for:\n",
        "- building reviewer sets `book_users[Title_canon]`,  \n",
        "- defining edges between books when at least two users reviewed both titles, and  \n",
        "- interpreting central books by their majority genre label `category_final`.\n",
        "\n",
        "In practice, this step prevents the PageRank-based ranking from artificially splitting influential works across multiple nodes, and stabilises both degree and overlap statistics in the co-review network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBjVtUKE0Rk6"
      },
      "source": [
        "### 6. Duplicate consolidation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzAUKmm7DVFd"
      },
      "source": [
        "### 6.1 Detection of suspicious duplicate canonical titles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqLqY7UXDZQ9"
      },
      "source": [
        "Even after the main `TitleCanonicalizer` step, some works may still appear under multiple very similar `Title_canon` strings\n",
        "(e.g. colon vs bracket variants, slightly different subtitles).  \n",
        "To detect these residual cases, a simplified normalised form `core_simple` is computed by lowercasing `Title_canon` and stripping all non-alphanumeric characters.\n",
        "\n",
        "Grouping `df_core` by `core_simple` and counting distinct `Title_canon` reveals clusters where several canonical titles collapse to the same simplified form.\n",
        "These clusters are stored in `suspicious_dict` and represent high-confidence duplicate candidates that can be harmonised without affecting genuinely distinct books.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbqOobm6DVRc"
      },
      "outputs": [],
      "source": [
        "def simple_core(t):\n",
        "    t = t.lower()\n",
        "    t = re.sub(r\"[^a-z0-9\\s]\", \" \", t)\n",
        "    return \" \".join(t.split())\n",
        "\n",
        "df_core[\"core_simple\"] = df_core[\"Title_canon\"].map(simple_core)\n",
        "\n",
        "group_sizes = df_core.groupby(\"core_simple\")[\"Title_canon\"].nunique()\n",
        "suspicious = group_sizes[group_sizes > 1]\n",
        "\n",
        "suspicious_dict = {}\n",
        "for core in suspicious.index:\n",
        "    titles = sorted(df_core[df_core[\"core_simple\"] == core][\"Title_canon\"].unique())\n",
        "    suspicious_dict[core] = titles\n",
        "\n",
        "print(\"Suspicious groups detected:\", len(suspicious_dict))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL87iOIADl_y"
      },
      "source": [
        "### 6.2 Harmonisation of suspicious duplicate groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqe1tYi7DmIn"
      },
      "source": [
        "For each group in `suspicious_dict`, the titles differ only by minor formatting or punctuation and refer to the same underlying work.\n",
        "To avoid creating multiple nodes for such variants, each group is collapsed to a single representative string, chosen as the shortest title in the group.\n",
        "\n",
        "The mapping `harmonisation_map` is then applied to `df_core[\"Title_canon\"]`, so all occurrences of that work share the same canonical label\n",
        "before building reviewer sets and edges.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3TqwxZ0Dx60"
      },
      "outputs": [],
      "source": [
        "harmonisation_map = {}\n",
        "\n",
        "for core, titles in suspicious_dict.items():\n",
        "    representative = min(titles, key=len)\n",
        "    for t in titles:\n",
        "        harmonisation_map[t] = representative\n",
        "\n",
        "df_core[\"Title_canon\"] = df_core[\"Title_canon\"].replace(harmonisation_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5QgceXXEntl"
      },
      "source": [
        "### 6.3 Deterministic consolidation of high-impact duplicate works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjyjlvj-EsHl"
      },
      "source": [
        "Automatic rules and `core_simple` harmonisation still leave a few prominent works split across edition-specific or annotated variants\n",
        "(e.g. boxed sets, study guides, anniversary editions).  \n",
        "Inspecting the most reviewed titles and the suspicious groups highlighted a small set of recurring cases\n",
        "such as *The Hobbit*, *The Lord of the Rings* boxed sets, *1984*, *Animal Farm*, *Jane Eyre*, and similar classics.\n",
        "\n",
        "To avoid over-complicating the normaliser, these high-impact cases are encoded explicitly in a small dictionary `manual_title_map`\n",
        "that maps edition-specific `Title_canon` labels to a single, stable representative for each work.\n",
        "This manual consolidation is applied only to a handful of very visible books, ensuring that the graph does not artificially fragment their degree and overlap structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8L4kjbhEn2I"
      },
      "outputs": [],
      "source": [
        "manual_title_map = {\n",
        "    # Hobbit family\n",
        "    \"The Hobbit There and Back Again\": \"The Hobbit\",\n",
        "    \"The Hobbitt, or there and back again; illustrated by the author.\": \"The Hobbit\",\n",
        "\n",
        "    # Lord of the Rings family\n",
        "    \"The Lord of the Rings - Boxed Set\":\n",
        "        \"The Lord of the Rings Trilogy (The Fellowship of the Ring, The Two Towers, The Return of the King, I, II, III)\",\n",
        "    \"The Lord Of The Rings THREE VOLUME BOXED SET (The Fellowship Of The Ring, The Return of The King, The Two towers)\":\n",
        "        \"The Lord of the Rings Trilogy (The Fellowship of the Ring, The Two Towers, The Return of the King, I, II, III)\",\n",
        "    \"The Lord of the Rings (3 Volume Set)\":\n",
        "        \"The Lord of the Rings Trilogy (The Fellowship of the Ring, The Two Towers, The Return of the King, I, II, III)\",\n",
        "    \"The Lord of the Rings Trilogy: Three Volumes in Slipcase\":\n",
        "        \"The Lord of the Rings Trilogy (The Fellowship of the Ring, The Two Towers, The Return of the King, I, II, III)\",\n",
        "\n",
        "    # Pride and Prejudice\n",
        "    \"Pride & Prejudice (Penguin Classics)\": \"Pride and Prejudice\",\n",
        "\n",
        "    # To Kill a Mockingbird\n",
        "    \"Harper Lee's To Kill a Mockingbird (Barron's Book Notes)\": \"To kill a mockingbird\",\n",
        "\n",
        "    # 1984 variants\n",
        "    \"Nineteen Eighty-four\": \"1984\",\n",
        "    \"George Orwell 1984\": \"1984\",\n",
        "\n",
        "    # Animal Farm variants\n",
        "    \"Animal Farm 50TH Anniversary Edition\": \"Animal Farm\",\n",
        "    \"ANIMAL FARM - A Fairy Story (Time Reading Program Special Edition)\": \"Animal Farm\",\n",
        "\n",
        "    # Christmas Carol variants\n",
        "    \"Christmas Carol (Ladybird Classics)\": \"A Christmas Carol (Classic Fiction)\",\n",
        "\n",
        "    # Jane Eyre variants\n",
        "    \"Jane Eyre: Complete and Unabridged (Puffin Classics)\": \"Jane Eyre\",\n",
        "\n",
        "    # The Red Tent\n",
        "    \"The Red Tent (Bestselling Backlist)\": \"The Red Tent\",\n",
        "    \"Red Tent\": \"The Red Tent\",\n",
        "\n",
        "    # In the Heart of the Sea\n",
        "    \"In the Heart of the Sea: The Tragedy of the Whaleship Essex\": \"In the Heart of the Sea\",\n",
        "\n",
        "    # The Lion, the Witch and the Wardrobe\n",
        "    \"The Lion, the Witch and the Wardrobe Movie Tie-in Edition\":\n",
        "    \"The Lion, the Witch and the Wardrobe\",\n",
        "    \"The Lion, the Witch and the Wardrobe Movie Tie-in Edition (The Chronicles of Narnia)\":\n",
        "    \"The Lion, the Witch and the Wardrobe\",\n",
        "    \"The Lion, the Witch and the Wardrobe Movie Tie-in Edition (T...whatever full string you see...)\":\n",
        "    \"The Lion, the Witch and the Wardrobe\",\n",
        "\n",
        "\n",
        "    # The Great Gatsby\n",
        "    \"Great Gatsby (Everyman)\": \"The Great Gatsby\",\n",
        "\n",
        "    # Suspicious small groups found earlier\n",
        "    \"Art Fundamentals (Theory and Practice)\": \"Art Fundamentals: Theory and Practice\",\n",
        "    \"Database Processing (Fundamentals, Design, and Implementation)\":\n",
        "        \"Database Processing: Fundamentals, Design and Implementation\",\n",
        "    \"Trophy Hunt (A JOE PICKETT NOVEL)\": \"Trophy Hunt: A Joe Pickett Novel\",\n",
        "    \"Warrior's Song (Medieval Song Quartet #4)\": \"Warrior's Song: Medieval Song Quartet #4\",\n",
        "}\n",
        "\n",
        "df_core[\"Title_canon\"] = df_core[\"Title_canon\"].replace(manual_title_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E1S2BTxFXL5"
      },
      "source": [
        "### 6.4 Recompute categories and clean duplicate (user, title) pairspairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wIYUUd0xc6G"
      },
      "source": [
        "After all automatic and manual merges, the category and interaction counts must be recomputed at the level of the final `Title_canon` labels.\n",
        "For each canonical title, the majority category over the original `categories` is stored in `category_final`,\n",
        "so that genres can later be used to interpret central books and communities.\n",
        "\n",
        "Merging titles can also create duplicate `(User_id, Title_canon)` pairs when a user reviewed several variants of the same work.\n",
        "These duplicates are dropped to obtain the final canonical interaction table that will feed reviewer-set construction and graph building.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2uXeT3kFXZ7"
      },
      "outputs": [],
      "source": [
        "cat_counts_core = (\n",
        "    df_core.groupby([\"Title_canon\", \"categories\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"n\")\n",
        ")\n",
        "\n",
        "top_category_core = (\n",
        "    cat_counts_core.sort_values([\"Title_canon\", \"n\"], ascending=[True, False])\n",
        "    .drop_duplicates(subset=[\"Title_canon\"])\n",
        "    .set_index(\"Title_canon\")[\"categories\"]\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "df_core[\"category_final\"] = df_core[\"Title_canon\"].map(top_category_core)\n",
        "\n",
        "# Remove duplicates produced by merging\n",
        "before = len(df_core)\n",
        "df_core = df_core.drop_duplicates(subset=[\"User_id\", \"Title_canon\"], keep=\"first\")\n",
        "after = len(df_core)\n",
        "\n",
        "print(\"Canonical titles after all merges:\", df_core[\"Title_canon\"].nunique())\n",
        "print(\"Final canonical interactions:\", after)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dUcO0g2xq2O"
      },
      "source": [
        "After automatic refinement, suspicious-group harmonisation, and targeted manual consolidation,\n",
        "the number of canonical titles stabilises at 16,160 and the final canonical core contains 568,954 user–book interactions.\n",
        "\n",
        "This means that a relatively small number of high-impact works were affected by manual decisions, while the vast majority of titles are handled purely by the automatic pipeline.\n",
        "At this point, each `Title_canon` represents a stable book-level node with:\n",
        "\n",
        "- a unique label used in reviewer sets and in the co-review graph,  \n",
        "- a majority-vote genre `category_final`, and  \n",
        "- at most one interaction per `(User_id, Title_canon)` pair.\n",
        "\n",
        "The resulting `df_core` is the definitive interaction table on which reviewer sets, MinHash/LSH candidate generation, edge construction, and PageRank-based ranking are built.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUdGwpKnGurV"
      },
      "source": [
        "### 7. Reviewer sets and LSH-based edge construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvkWxRZzG1h-"
      },
      "source": [
        "#### 7.1 Reviewer sets for canonical titles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WA5oYD-G914"
      },
      "source": [
        "At this stage, each row of `df_core` is a cleaned interaction between a user and a canonical book title.\n",
        "To construct book–book links, the first step is to invert this table and build a mapping:\n",
        "\n",
        "- `book_users[Title_canon] = set of user IDs that reviewed this book`.\n",
        "\n",
        "These reviewer sets are the basic objects used to measure co-review overlap.\n",
        "The summary statistics on `reviewers_per_book` show how many distinct users are attached to each canonical title,\n",
        "which will later drive the strength and reliability of edges in the co-review graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_DQ3de-Gu0t"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "book_users = defaultdict(set)\n",
        "\n",
        "for row in df_core.itertuples(index=False):\n",
        "    book = row.Title_canon\n",
        "    user = str(row.User_id)\n",
        "    book_users[book].add(user)\n",
        "\n",
        "n_books = len(book_users)\n",
        "reviewers_per_book = pd.Series(\n",
        "    {b: len(u) for b, u in book_users.items()},\n",
        "    name=\"n_reviewers\"\n",
        ")\n",
        "\n",
        "print(f\"Distinct canonical titles in reviewer sets: {n_books:,}\")\n",
        "print(\"\\nReviewers per canonical title:\")\n",
        "print(\n",
        "    reviewers_per_book.describe(\n",
        "        percentiles=[0.50, 0.75, 0.90, 0.99]\n",
        "    )\n",
        ")\n",
        "\n",
        "assert reviewers_per_book.min() >= 1, \"Found a title with zero reviewers.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddMw5HL5HVsi"
      },
      "source": [
        "#### 7.2 MinHash signatures and LSH index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHeMM-hrHNiF"
      },
      "source": [
        "Computing exact reviewer-set overlaps for all book pairs would be quadratic in the number of titles and infeasible on this dataset.\n",
        "To obtain a scalable approximation, each `book_users[title]` set is compressed into a MinHash signature of length `NUM_PERM`.\n",
        "\n",
        "These signatures are indexed in a `MinHashLSH` structure with a Jaccard threshold `LSH_THRESHOLD`.\n",
        "For each title, the LSH index returns only a small set of candidate neighbours with potentially non-negligible Jaccard similarity,\n",
        "so that exact overlaps are computed only for promising pairs instead of for all possible combinations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h75FNhOMHNuk"
      },
      "outputs": [],
      "source": [
        "from datasketch import MinHash, MinHashLSH\n",
        "\n",
        "NUM_PERM = 128             # number of hash permutations\n",
        "LSH_THRESHOLD = 0.1        # Jaccard threshold for candidate generation\n",
        "MIN_COMMON_REVIEWERS = 2   # minimum shared reviewers to keep an edge (project requirement)\n",
        "\n",
        "def build_minhash(user_set, num_perm=NUM_PERM):\n",
        "    \"\"\"Create a MinHash object from a set of user IDs.\"\"\"\n",
        "    m = MinHash(num_perm=num_perm)\n",
        "    for u in user_set:\n",
        "        m.update(u.encode(\"utf-8\"))\n",
        "    return m\n",
        "\n",
        "print(\"Building MinHash signatures for canonical titles...\")\n",
        "\n",
        "book_ids = list(book_users.keys())\n",
        "minhashes = {b: build_minhash(book_users[b]) for b in book_ids}\n",
        "\n",
        "print(f\"MinHashes created for {len(minhashes):,} canonical titles.\")\n",
        "\n",
        "print(\"Indexing MinHashes in LSH...\")\n",
        "lsh = MinHashLSH(threshold=LSH_THRESHOLD, num_perm=NUM_PERM)\n",
        "\n",
        "for b in book_ids:\n",
        "    lsh.insert(b, minhashes[b])\n",
        "\n",
        "print(\"LSH indexing completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0izyxFkHhrU"
      },
      "source": [
        "#### 7.3 Candidate pairs and exact intersection edge construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swrYQe7JIPPk"
      },
      "source": [
        "Using the LSH index, each title is matched only against a reduced set of candidate neighbours.\n",
        "For each candidate pair `(b, c)`, the code:\n",
        "\n",
        "1. Enforces a fixed ordering and tracks `seen_pairs` to avoid duplicates,  \n",
        "2. Computes the exact intersection size `|book_users[b] ∩ book_users[c]|`,  \n",
        "3. Keeps an undirected edge `(b, c, w)` only if `w ≥ MIN_COMMON_REVIEWERS`.\n",
        "\n",
        "Setting `MIN_COMMON_REVIEWERS = 2` enforces the Project 3 requirement:\n",
        "two books are linked only if **at least two distinct users** reviewed both.\n",
        "The resulting list `edges` is a sparse but informative representation of co-review similarity,\n",
        "with weights equal to the number of shared reviewers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e55OE92lIPZb"
      },
      "outputs": [],
      "source": [
        "edges = []          # list of (book1, book2, common_reviewers)\n",
        "seen_pairs = set()  # to avoid duplicates\n",
        "\n",
        "print(\"Generating candidate edges via LSH and checking exact overlaps...\")\n",
        "\n",
        "for i, b in enumerate(book_ids):\n",
        "    candidates = lsh.query(minhashes[b])\n",
        "\n",
        "    for c in candidates:\n",
        "        if c == b:\n",
        "            continue\n",
        "\n",
        "        pair = tuple(sorted((b, c)))\n",
        "        if pair in seen_pairs:\n",
        "            continue\n",
        "        seen_pairs.add(pair)\n",
        "\n",
        "        users_b = book_users[pair[0]]\n",
        "        users_c = book_users[pair[1]]\n",
        "        common = len(users_b & users_c)\n",
        "\n",
        "        if common >= MIN_COMMON_REVIEWERS:\n",
        "            edges.append((pair[0], pair[1], common))\n",
        "\n",
        "    if (i + 1) % 500 == 0:\n",
        "        print(f\"  processed {i+1:,} / {len(book_ids):,} canonical titles...\")\n",
        "\n",
        "print(f\"\\nTotal edges with ≥ {MIN_COMMON_REVIEWERS} shared reviewers: {len(edges):,}\")\n",
        "\n",
        "common_counts = pd.Series([w for _, _, w in edges], name=\"n_common_reviewers\")\n",
        "print(\"\\nDistribution of common reviewers per edge:\")\n",
        "print(common_counts.describe(percentiles=[0.5, 0.75, 0.9, 0.99]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-WS67Eg1Kz4"
      },
      "source": [
        "The reviewer-set inversion and LSH-based candidate generation produce:\n",
        "\n",
        "- 16,160 canonical titles with at least one reviewer, and  \n",
        "- 40,813 undirected edges where two books share at least two distinct users.\n",
        "\n",
        "The distribution of `n_common_reviewers` is strongly skewed:  \n",
        "most edges correspond to pairs with only 2–4 shared users, while a small minority reach dozens or even hundreds of common reviewers.\n",
        "\n",
        "This structure matches the intuition behind co-review networks:\n",
        "most book pairs are weakly related, but a few pairs are tied together by large, overlapping audiences.\n",
        "The `edges` list obtained here is the final input for constructing the weighted book–book graph in the next section, where each edge weight encodes the strength of this shared readership.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKLQXsMD0-lc"
      },
      "source": [
        "### 8. Co-Review Graph Construction and Network Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWhiRJQHIzuv"
      },
      "source": [
        "#### 8.1 Graph construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHmM-UhII585"
      },
      "source": [
        "The reviewer-overlap edges computed in Section 7 are now assembled into an undirected weighted graph `G`.\n",
        "Each canonical title becomes a node, annotated with its total number of reviewers (`n_reviewers`),\n",
        "and an edge `(b1, b2, w)` is added whenever two books share at least `w ≥ 2` distinct reviewers.\n",
        "\n",
        "The edge weights encode the strength of co-review similarity and form the input structure for all subsequent analyses:\n",
        "connected components, network sparsity, and PageRank-based ranking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNZ2vydUI1P4"
      },
      "outputs": [],
      "source": [
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes with attribute: number of reviewers\n",
        "for b, users in book_users.items():\n",
        "    G.add_node(b, n_reviewers=len(users))\n",
        "\n",
        "# Add weighted edges (shared reviewers)\n",
        "for b1, b2, w in edges:\n",
        "    G.add_edge(b1, b2, weight=w)\n",
        "\n",
        "print(\"Graph construction complete.\")\n",
        "print(f\"Number of nodes (canonical titles): {G.number_of_nodes():,}\")\n",
        "print(f\"Number of edges                   : {G.number_of_edges():,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N69dzJa1JEvw"
      },
      "source": [
        "#### 8.2 Network summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "disynERk2jvH"
      },
      "source": [
        "Basic structural statistics characterise the co-review graph before focusing on the largest connected component.\n",
        "\n",
        "- **Node/edge counts** show the overall scale.\n",
        "- **Degree distribution** indicates how many other books each title is linked to.\n",
        "- **Network density** quantifies sparsity (expected to be extremely low).\n",
        "- **Connected components** reveal whether the graph forms one large audience-sharing ecosystem\n",
        "  or many isolated clusters corresponding to niche genres or rarely reviewed works.\n",
        "\n",
        "The size and coverage of the largest connected component (LCC) determine the subset of titles on which PageRank can be computed meaningfully.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73O1A9vlJFkm"
      },
      "outputs": [],
      "source": [
        "num_nodes = G.number_of_nodes()\n",
        "num_edges = G.number_of_edges()\n",
        "\n",
        "print(f\"Total books (nodes) : {num_nodes:,}\")\n",
        "print(f\"Total edges         : {num_edges:,}\")\n",
        "\n",
        "# Degree statistics\n",
        "degrees = np.array([deg for _, deg in G.degree()])\n",
        "if len(degrees) > 0:\n",
        "    print(\"\\nDegree statistics:\")\n",
        "    print(f\"  mean degree   : {degrees.mean():.2f}\")\n",
        "    print(f\"  median degree : {np.median(degrees):.2f}\")\n",
        "    print(f\"  min degree    : {degrees.min():.0f}\")\n",
        "    print(f\"  max degree    : {degrees.max():.0f}\")\n",
        "else:\n",
        "    print(\"\\nGraph has no edges.\")\n",
        "\n",
        "# Network density\n",
        "density = nx.density(G)\n",
        "print(f\"\\nNetwork density: {density:.6f}\")\n",
        "\n",
        "# Connected components\n",
        "components = list(nx.connected_components(G))\n",
        "num_components = len(components)\n",
        "largest_component = max(components, key=len) if components else set()\n",
        "\n",
        "print(f\"\\nConnected components       : {num_components:,}\")\n",
        "print(f\"Largest component size     : {len(largest_component):,}\")\n",
        "if num_nodes > 0:\n",
        "    frac_lcc = len(largest_component) / num_nodes\n",
        "    print(f\"Fraction of nodes in LCC   : {frac_lcc:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCVdHX9JJa2n"
      },
      "source": [
        "#### 8.3 Degree & edge-weight distributions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFOq9zl52w7I"
      },
      "source": [
        "To inspect the structural shape of the graph, the degree distribution and edge-weight distribution\n",
        "are plotted on a logarithmic scale.\n",
        "\n",
        "- The **degree distribution** indicates how many other books each title is connected to\n",
        "  through at least two shared reviewers.\n",
        "- The **edge-weight distribution** describes how strongly linked these pairs are,\n",
        "  based on the number of common reviewers.\n",
        "\n",
        "Log-scaling highlights long-tail behaviour typical of real-world audience-overlap networks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tWX1sj4JbA1"
      },
      "outputs": [],
      "source": [
        "if num_edges > 0:\n",
        "    # Degree distribution\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.hist(degrees, bins=40)\n",
        "    plt.xlabel(\"Degree\")\n",
        "    plt.ylabel(\"Number of books\")\n",
        "    plt.title(\"Degree distribution (log scale)\")\n",
        "    plt.yscale(\"log\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Edge-weight distribution (number of shared reviewers)\n",
        "    edge_weights = np.array([w for _, _, w in G.edges(data=\"weight\")])\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.hist(edge_weights, bins=40)\n",
        "    plt.xlabel(\"Number of shared reviewers (edge weight)\")\n",
        "    plt.ylabel(\"Number of edges\")\n",
        "    plt.title(\"Edge weight distribution (log scale)\")\n",
        "    plt.yscale(\"log\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryo4pFF93C0S"
      },
      "source": [
        "The constructed co-review graph is extremely sparse, with density ≈ 0.000313,\n",
        "yet it contains enough structure to support meaningful ranking.\n",
        "\n",
        "**Degree distribution.**  \n",
        "The majority of books have degree 0–5, indicating that most titles share audiences with only a few others.  \n",
        "However, the long right tail (max degree = 104) reveals a small set of highly connected books—typically popular works reviewed by broad audiences.  \n",
        "This heavy-tailed pattern is characteristic of real-world bipartite-projection networks.\n",
        "\n",
        "**Edge-weight distribution.**  \n",
        "Most links correspond to only 2–4 shared reviewers, but a small fraction of edges reach hundreds or even over a thousand shared users.  \n",
        "These high-weight edges signify strong audience overlap and will play an important role in positioning hubs within a cluster.\n",
        "\n",
        "**Connected components.**  \n",
        "The graph fragments into **6,509 components**, but the largest connected component (LCC) contains **8,687 books**,  \n",
        "covering **53.76% of all nodes**.  \n",
        "Only nodes in the LCC participate in a globally connected recommendation structure,\n",
        "and PageRank is meaningful only on this subgraph.\n",
        "\n",
        "This component therefore becomes the focus of the ranking analysis in the next section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJu_sYC_KO_t"
      },
      "source": [
        "### 9. PageRank on the Largest Connected Component"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMWOEfYF1QaO"
      },
      "source": [
        "#### 9.1 Extract LCC and compute weighted PageRank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9TkTxg-1SgK"
      },
      "source": [
        "In Project 3 we must implement a ranking based on the **PageRank index**, where\n",
        "> “books are linked together if they have been reviewed at least by two different users.”\n",
        "\n",
        "In our graph `G`:\n",
        "* each node is a **canonical title** (`Title_canon`);\n",
        "* an undirected edge `(b1, b2)` exists if at least 2 users reviewed both books;\n",
        "* the edge weight `weight` equals the **number of shared reviewers**.\n",
        "\n",
        "Here we first extract the **largest connected component** (`G_lcc`) of `G`.  \n",
        "PageRank is then computed on `G_lcc` using `networkx.pagerank`, with:\n",
        "* `alpha = 0.85` = damping factor (probability that the random surfer **follows an edge**);\n",
        "* `1 − alpha` = teleport probability (jump to a random node);\n",
        "* `weight=\"weight\"` = transitions biased by the **number of shared reviewers**.\n",
        "\n",
        "This matches the PageRank definition: a stationary distribution of a random walk on the graph, here interpreted as a “random reader” who keeps moving between **co-reviewed books**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHZu02Ne1TFX"
      },
      "outputs": [],
      "source": [
        "if G.number_of_nodes() == 0 or G.number_of_edges() == 0:\n",
        "    raise ValueError(\"Graph is empty — earlier preprocessing must be checked.\")\n",
        "\n",
        "# Identify the largest connected component\n",
        "largest_cc = max(nx.connected_components(G), key=len)\n",
        "G_lcc = G.subgraph(largest_cc).copy()\n",
        "\n",
        "print(f\"LCC size: {G_lcc.number_of_nodes():,} nodes, {G_lcc.number_of_edges():,} edges\")\n",
        "\n",
        "# Compute weighted PageRank\n",
        "pagerank_scores = nx.pagerank(G_lcc, alpha=0.85, weight=\"weight\")\n",
        "\n",
        "# Store PageRank in node attributes\n",
        "nx.set_node_attributes(G_lcc, pagerank_scores, \"pagerank\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1bu8hG5-exd"
      },
      "source": [
        "The LCC `G_lcc` contains **8,687 books** and **39,661 edges**, i.e. more than half of all titles in `G`.  \n",
        "This is the main connected “reading universe” of the dataset; all subsequent rankings are computed on `G_lcc`, where PageRank can propagate influence along paths of co-reviewed books.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq9AxWAJ1e9E"
      },
      "source": [
        "#### 9.2 Build PageRank DataFrame with structural descriptors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erOUcHmx-3B7"
      },
      "source": [
        "The dictionary `pagerank_scores` (keys = `Title_canon`, values = PageRank) is\n",
        "converted into a dataframe `pr_df`.  \n",
        "Three structural descriptors are then attached:\n",
        "\n",
        "* `degree` — degree of the node in `G_lcc` (number of neighbour books).\n",
        "* `n_reviewers` — size of the set `book_users[Title_canon]`\n",
        "  (distinct users who reviewed the book in the canonical core).\n",
        "* `n_reviews` — total number of canonical reviews of the book in `df_core`.\n",
        "\n",
        "Finally, `pr_df` is sorted by `pagerank` in descending order.  \n",
        "This table is the central object for later analyses comparing **PageRank** to simpler popularity proxies such as number of reviews or number of reviewers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D84iJvsq1eqI"
      },
      "outputs": [],
      "source": [
        "pr_df = (\n",
        "    pd.DataFrame.from_dict(pagerank_scores, orient=\"index\", columns=[\"pagerank\"])\n",
        "    .rename_axis(\"Title_canon\")\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Degree in the LCC\n",
        "deg_dict = dict(G_lcc.degree())\n",
        "pr_df[\"degree\"] = pr_df[\"Title_canon\"].map(deg_dict)\n",
        "\n",
        "# Number of unique reviewers per book\n",
        "pr_df[\"n_reviewers\"] = pr_df[\"Title_canon\"].map(\n",
        "    lambda t: len(book_users.get(t, set()))\n",
        ")\n",
        "\n",
        "# Number of reviews in the canonical interaction table\n",
        "reviews_per_title = df_core[\"Title_canon\"].value_counts()\n",
        "pr_df[\"n_reviews\"] = pr_df[\"Title_canon\"].map(reviews_per_title)\n",
        "\n",
        "# Sort by PageRank score\n",
        "pr_df = pr_df.sort_values(\"pagerank\", ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqneIDvn_lWI"
      },
      "source": [
        "Each row in `pr_df` now summarises a book with:\n",
        "* its PageRank score (`pagerank`);\n",
        "* its local connectivity in the co-review graph (`degree`);\n",
        "* how many users touched it at least once (`n_reviewers`);\n",
        "* how many reviews it has after canonicalisation (`n_reviews`).\n",
        "\n",
        "This makes it easy to check whether PageRank is just reproducing raw popularity\n",
        "or is capturing something more structural about how books are positioned in the\n",
        "reviewer–overlap network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxaFw8v11qhn"
      },
      "source": [
        "#### 9.3 Top 20 books by PageRank\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3V1KsBd_rSX"
      },
      "source": [
        "A compact top-20 ranking is printed to inspect the titles with the highest\n",
        "`pagerank` scores, together with their degree and number of reviews.\n",
        "This quick diagnostic output helps identify which books occupy central\n",
        "positions in the co-review graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLB90zTm1qqe"
      },
      "outputs": [],
      "source": [
        "print(\"\\nTop 20 books by PageRank:\")\n",
        "for rank, (_, row) in enumerate(pr_df.head(20).iterrows(), start=1):\n",
        "    print(\n",
        "        f\"{rank:2d}. \"\n",
        "        f\"{row['Title_canon'][:60]:60s}  \"\n",
        "        f\"PR={row['pagerank']:.6f}  \"\n",
        "        f\"deg={row['degree']:4d}  \"\n",
        "        f\"reviews={int(row['n_reviews']):4d}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLwM0gxoBPbE"
      },
      "source": [
        "The top PageRank titles combine substantial reviewer overlap with relatively\n",
        "high degrees inside the co-review graph. Several of the leading books have\n",
        "moderate review counts but large neighbourhoods, indicating that PageRank is\n",
        "picking out titles positioned at the intersection of multiple reviewer\n",
        "communities rather than simply the most-reviewed items.  \n",
        "\n",
        "This behaviour is consistent with the goal of Project 3: the ranking is driven by\n",
        "how books connect through shared reviewing activity, so titles that serve as\n",
        "bridges across different clusters receive higher scores even when their raw\n",
        "popularity is not extreme.  \n",
        "The result confirms that the link-based ranking reflects structural influence in\n",
        "the dataset rather than a direct proxy for volume of reviews.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1L9iXvL2fc6"
      },
      "source": [
        "### 10. Metadata Join for Ranking Table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmwStGyp2ifd"
      },
      "source": [
        "#### 10.1 Add average rating and category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta3xAKqv2tI_"
      },
      "source": [
        "In this step the PageRank table `pr_df` is enriched with two pieces of metadata\n",
        "taken from the canonical interaction core `df_core`:\n",
        "\n",
        "* `avg_rating` — mean `review/score` for each `Title_canon`,\n",
        "* `category_final` — dominant category label for each canonical title\n",
        "  (already resolved during title normalisation).\n",
        "\n",
        "This makes it possible to compare structural centrality (PageRank) with more\n",
        "standard signals such as perceived quality and genre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff6rX0MJ2q7m"
      },
      "outputs": [],
      "source": [
        "# Average rating per canonical title\n",
        "avg_rating = (\n",
        "    df_core\n",
        "    .groupby(\"Title_canon\")[\"review/score\"]\n",
        "    .mean()\n",
        ")\n",
        "\n",
        "pr_df[\"avg_rating\"] = pr_df[\"Title_canon\"].map(avg_rating)\n",
        "\n",
        "# Category: majority label per canonical title\n",
        "title_to_cat = (\n",
        "    df_core\n",
        "    .groupby(\"Title_canon\")[\"category_final\"]\n",
        "    .agg(lambda x: x.iloc[0])   # category_final already chosen per title\n",
        ")\n",
        "\n",
        "pr_df[\"category_final\"] = pr_df[\"Title_canon\"].map(title_to_cat)\n",
        "\n",
        "print(\"Non-null avg_rating entries:\", pr_df[\"avg_rating\"].notna().sum())\n",
        "print(\"Non-null category entries  :\", pr_df[\"category_final\"].notna().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLVvpTcGEONd"
      },
      "source": [
        "The printout confirms that all books in the LCC now carry both an average rating\n",
        "and a category label. This enriches the ranking table and enables comparisons\n",
        "between structural influence, popularity, and quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiHk1eeS2qvE"
      },
      "source": [
        "#### 10.2 Compute ranking indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBzJhsTZEtkT"
      },
      "source": [
        "Three ranking indices are added to `pr_df`:\n",
        "\n",
        "* `rank_pr`   — rank induced by the PageRank score (1 = highest);\n",
        "* `rank_pop`  — rank induced by the number of canonical reviews `n_reviews`;\n",
        "* `rank_qual` — rank induced by the average rating `avg_rating`.\n",
        "\n",
        "All ranks are computed using `method=\"min\"`, so tied values share the same best\n",
        "rank. These indices make it possible to directly compare the PageRank ranking\n",
        "with simpler baselines based on popularity or rating.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZMMPNRO26wo"
      },
      "outputs": [],
      "source": [
        "pr_df[\"rank_pr\"]   = pr_df[\"pagerank\"].rank(ascending=False, method=\"min\").astype(int)\n",
        "pr_df[\"rank_pop\"]  = pr_df[\"n_reviews\"].rank(ascending=False, method=\"min\").astype(int)\n",
        "pr_df[\"rank_qual\"] = pr_df[\"avg_rating\"].rank(ascending=False, method=\"min\").astype(int)\n",
        "\n",
        "print(\"Columns in pr_df:\", pr_df.columns.tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AalQ2MXREmpV"
      },
      "source": [
        "Each title now has a position in three ranking systems: structural (PageRank),\n",
        "popularity-based (number of reviews), and quality-based (average rating).\n",
        "This forms the basis for identifying books whose structural role in the network\n",
        "differs from their surface-level popularity or perceived quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Jb92kc46lk"
      },
      "source": [
        "### 11. PageRank Diagnostics & Comparisons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_W1-F1X5APx"
      },
      "source": [
        "#### 11.1 PageRank vs popularity (review count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iFHCMpvI1gz"
      },
      "source": [
        "This block compares the PageRank score of each book (`pagerank`) with its total number of canonical reviews (`n_reviews`). A hexbin plot is used, both axes are on a log scale, so dense regions correspond to many books with similar popularity and influence.\n",
        "\n",
        "The Pearson correlation\n",
        "\n",
        "`corr_pr_pop = pr_df[\"pagerank\"].corr(pr_df[\"n_reviews\"])`\n",
        "\n",
        "\n",
        "quantifies how strongly PageRank aligns with plain review count.\n",
        "In this run the value is about **0.24**, which indicates only a **weak–moderate**  positive relationship: very popular books tend to have higher PageRank, but popularity alone does not explain structural influence in the co-review graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cgOFVLz46vJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7,6))\n",
        "plt.hexbin(\n",
        "    pr_df[\"n_reviews\"], pr_df[\"pagerank\"],\n",
        "    gridsize=40, bins=\"log\", cmap=\"PuBu\",\n",
        "    xscale=\"log\", yscale=\"log\"\n",
        ")\n",
        "plt.xlabel(\"Number of reviews (log)\")\n",
        "plt.ylabel(\"PageRank (log)\")\n",
        "plt.title(\"PageRank vs Review Count\")\n",
        "plt.colorbar(label=\"log(count)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "corr_pr_pop = pr_df[\"pagerank\"].corr(pr_df[\"n_reviews\"])\n",
        "print(\"Correlation(PageRank, n_reviews):\", corr_pr_pop)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umc2cG_G5Iz8"
      },
      "source": [
        "#### 11.2 PageRank vs degree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldow_nxKJ6mM"
      },
      "source": [
        "Here the x–axis uses each title’s degree in the LCC (`degree`), i.e. the number of neighbouring books linked via shared reviewers. The y–axis is the PageRank score.\n",
        "\n",
        "The Pearson correlation\n",
        "\n",
        "`corr_pr_deg = pr_df[\"degree\"].corr(pr_df[\"pagerank\"])`\n",
        "\n",
        "is about **0.74**, substantially higher than for review count. This suggests that PageRank is far more aligned with **how many distinct neighbours a book connects** than with how many reviews it accumulates.  \n",
        "High-PageRank titles tend to sit at the intersection of many reading communities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCh-VHpa5KGy"
      },
      "outputs": [],
      "source": [
        "x_deg = pr_df[\"degree\"].replace(0, np.nan)\n",
        "y_pr  = pr_df[\"pagerank\"]\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.hexbin(\n",
        "    x_deg, y_pr,\n",
        "    gridsize=40, bins=\"log\", cmap=\"PuBu\",\n",
        "    xscale=\"log\", yscale=\"log\"\n",
        ")\n",
        "plt.xlabel(\"Degree (log)\")\n",
        "plt.ylabel(\"PageRank (log)\")\n",
        "plt.title(\"PageRank vs Degree\")\n",
        "plt.colorbar(label=\"log(count)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "corr_pr_deg = pr_df[\"degree\"].corr(pr_df[\"pagerank\"])\n",
        "print(\"Correlation(PageRank, degree):\", corr_pr_deg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-faj5k6AKE-Q"
      },
      "source": [
        "The hexbin shows a clear increasing trend, and the correlation is around 0.74, substantially higher than for review count.\n",
        "This suggests that PageRank is much more aligned with how many different neighbours a book bridges than with how many reviews it collects: high-PageRank titles tend to sit on many co-review links, not just accumulate ratings in isolation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qncVFeMFNIUQ"
      },
      "source": [
        "#### 11.3 PageRank vs Average Rating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ3IatW6PfGR"
      },
      "source": [
        "Average ratings in the dataset occupy a very narrow band (most titles lie between 3.5 and 4.7), and many books share identical mean scores. Because of this low variance, a scatter or hexbin plot is not informative. Instead the diagnostic relies on the Pearson correlation:\n",
        "\n",
        "`corr_pr_rating = pr_df[\"pagerank\"].corr(pr_df[\"avg_rating\"])`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-RBbbqwNIcy"
      },
      "outputs": [],
      "source": [
        "corr_pr_rating = pr_df[\"pagerank\"].corr(pr_df[\"avg_rating\"])\n",
        "print(\"Correlation(PageRank, avg_rating):\", corr_pr_rating)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eChkZ4bzQSvO"
      },
      "source": [
        "\n",
        "In this run the correlation is approximately **0.015**, effectively zero.\n",
        "This shows that **perceived quality (average rating) and structural influence (PageRank) are almost completely independent**.\n",
        "\n",
        "A book can be highly rated yet occupy a peripheral position in the co-review network, and conversely a structurally central book does not necessarily receive the highest scores. PageRank therefore captures a dimension of influence not reflected in user ratings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 11.4 Popularity vs Connectivity vs Prestige (Top-20 by PageRank)"
      ],
      "metadata": {
        "id": "nFIap26LqiBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare network-based influence with traditional popularity measures, the top-20 titles by PageRank are evaluated along three dimensions:\n",
        "\n",
        "- **Popularity:** total number of reviews (`n_reviews`)\n",
        "- **Connectivity:** degree in the LCC (`degree`)\n",
        "- **Prestige:** PageRank score (`pagerank`)\n",
        "\n",
        "Each metric is min–max normalised within the top-20 set to enable direct visual comparison on the same scale.\n"
      ],
      "metadata": {
        "id": "BYgIVOqgqb7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-20 by prestige: popularity vs connectivity vs prestige\n",
        "\n",
        "top20 = pr_df.sort_values(\"rank_pr\").head(20).copy()\n",
        "\n",
        "# Select metrics\n",
        "top20[\"popularity\"]    = top20[\"n_reviews\"].astype(float)\n",
        "top20[\"connectivity\"]  = top20[\"degree\"].astype(float)\n",
        "top20[\"prestige\"]      = top20[\"pagerank\"].astype(float)\n",
        "\n",
        "# Min-max normalisation within the top-20 (for comparability)\n",
        "def minmax(s):\n",
        "    s = s.astype(float)\n",
        "    rng = s.max() - s.min()\n",
        "    return (s - s.min()) / rng if rng != 0 else 0.0*s\n",
        "\n",
        "top20[\"pop_norm\"]  = minmax(top20[\"popularity\"])\n",
        "top20[\"deg_norm\"]  = minmax(top20[\"connectivity\"])\n",
        "top20[\"pr_norm\"]   = minmax(top20[\"prestige\"])\n",
        "\n",
        "# Short labels (ASIN is compact; title labels would be unreadable)\n",
        "labels = top20[\"asin\"].astype(str).tolist() if \"asin\" in top20.columns else [str(i) for i in range(1, 21)]\n",
        "\n",
        "x = np.arange(len(top20))\n",
        "w = 0.28\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.bar(x - w, top20[\"pop_norm\"], width=w, label=\"Popularity (reviews)\")\n",
        "plt.bar(x,      top20[\"deg_norm\"], width=w, label=\"Connectivity (degree)\")\n",
        "plt.bar(x + w,  top20[\"pr_norm\"],  width=w, label=\"Prestige (PageRank)\")\n",
        "\n",
        "plt.xticks(x, labels, rotation=90)\n",
        "plt.ylabel(\"Normalised score (0–1)\")\n",
        "plt.title(\"Top-20 by PageRank: Popularity vs Connectivity vs Prestige\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YgAl3Jn_qKWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Popularity, connectivity, and prestige differ substantially among the top-20 titles.\n",
        "PageRank highlights books that are central in the co-review structure, not necessarily the most reviewed or most connected ones.\n"
      ],
      "metadata": {
        "id": "Sr5-qouurrPy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rQDSk7q5O0G"
      },
      "source": [
        "#### 11.4 Compute rank-shift (overrated / underrated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jyHBYXQOlJK"
      },
      "source": [
        "A rank-shift index is defined as:\n",
        "\n",
        "`pr_df[\"rank_shift_pop\"] = pr_df[\"rank_pop\"] - pr_df[\"rank_pr\"]`\n",
        "\n",
        "where:\n",
        "\n",
        "* `rank_pop` = rank induced by `n_reviews` (1 = most reviewed)  \n",
        "* `rank_pr`  = rank induced by PageRank (1 = highest PageRank)\n",
        "\n",
        "By construction:\n",
        "\n",
        "* **`rank_shift_pop > 0`** → PageRank rank is better → **structurally underrated** books  \n",
        "* **`rank_shift_pop < 0`** → popularity rank is better → **structurally overrated** books  \n",
        "\n",
        "This index is the simplest way to detect discrepancies between raw popularity  \n",
        "and network-based influence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b-xeAoy5yYZ"
      },
      "source": [
        "#### 11.7 Genre distribution among top PageRank titles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYUN-yfrPPTX"
      },
      "source": [
        "The top-20 books by PageRank are extracted and their `category_final` labels are counted. A simple bar plot shows the distribution of genres.\n",
        "\n",
        "The resulting mix demonstrates that high-PageRank hubs are drawn from several categories, not dominated by a single genre. This indicates that the co-review graph is capturing **cross-genre bridges** instead of overfitting to one segment of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thsoI3nX501A"
      },
      "outputs": [],
      "source": [
        "top20 = pr_df.head(20)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "top20[\"category_final\"].value_counts().plot(kind=\"bar\")\n",
        "plt.xlabel(\"Category\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top-20 PageRank: Category Distribution\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKm75TiBPt5-"
      },
      "source": [
        "Taken together, these diagnostics show that:\n",
        "\n",
        "* PageRank correlates **weakly** with raw popularity and **strongly** with degree, confirming that the implemented ranking is **structure-driven**.\n",
        "\n",
        "* The rank-shift analysis clearly separates **overrated** (popular but structurally peripheral) from **underrated** (moderately popular but structurally central) titles.\n",
        "\n",
        "* The genre composition of top-PageRank titles demonstrates that structural hubs span multiple categories, validating PageRank as a tool for identifying books that connect different parts of the readership network.\n",
        "\n",
        "These findings directly address the core requirement of Project 3: showing how a PageRank-based ranking differs from simpler heuristics and why structural centrality provides additional information beyond raw popularity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH9vm_mk7zfw"
      },
      "source": [
        "### 12. Centrality Measures on G_lcc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-5uWDHy8Ls-"
      },
      "source": [
        "#### 12.1 Degree, closeness, betweenness centrality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW2_TCYaTmDP"
      },
      "source": [
        "This block computes three standard node–level centrality indices on the\n",
        "largest connected component `G_lcc`:\n",
        "\n",
        "- `deg_centrality` – normalised degree centrality from `nx.degree_centrality(G_lcc)`, i.e. how many neighbours a book has compared to the maximum possible.\n",
        "- `closeness` – closeness centrality from `nx.closeness_centrality(G_lcc)`, which is high for books that are, on average, at short graph distance from all others.\n",
        "- `betweenness` – betweenness centrality from `nx.betweenness_centrality(G_lcc, weight=\"weight\")`, which is high for books lying on many shortest paths between other titles (bridge nodes).\n",
        "\n",
        "All three indices are stored in `centrality_df`, and the helper function `print_top(...)` prints the top-10 titles for each metric. This is used as a qualitative diagnostic to see which books act as high-degree hubs, global “centres” (high closeness), or structural bridges (high betweenness) in the reviewer-overlap network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9ZQ68kj8RrB"
      },
      "outputs": [],
      "source": [
        "deg_cent = nx.degree_centrality(G_lcc)\n",
        "close_cent = nx.closeness_centrality(G_lcc)\n",
        "betw_cent = nx.betweenness_centrality(G_lcc, weight=\"weight\")\n",
        "\n",
        "centrality_df = pd.DataFrame({\n",
        "    \"Title_canon\": list(G_lcc.nodes()),\n",
        "    \"deg_centrality\": [deg_cent[n] for n in G_lcc.nodes()],\n",
        "    \"closeness\":      [close_cent[n] for n in G_lcc.nodes()],\n",
        "    \"betweenness\":    [betw_cent[n] for n in G_lcc.nodes()],\n",
        "})\n",
        "\n",
        "def print_top(df, col, k=10):\n",
        "    print(f\"\\nTop {k} books by {col}:\")\n",
        "    top = df.sort_values(col, ascending=False).head(k)\n",
        "    for i, row in enumerate(top.itertuples(), start=1):\n",
        "        print(f\"{i:2d}. {row.Title_canon[:60]:60s}  {col}={getattr(row, col):.4f}\")\n",
        "\n",
        "print_top(centrality_df, \"deg_centrality\")\n",
        "print_top(centrality_df, \"closeness\")\n",
        "print_top(centrality_df, \"betweenness\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "483NTJOd8UrD"
      },
      "source": [
        "#### 12.2 Community detection (Louvain) + genre mix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSduoLaBUJdx"
      },
      "source": [
        "Here the graph `G_lcc` is partitioned into communities using the\n",
        "Louvain algorithm:\n",
        "\n",
        "- `louvain_communities(G_lcc, weight=\"weight\", seed=42)` returns a list\n",
        "  of sets, each set being a community of titles with dense internal connections.\n",
        "- Each node is mapped to a community id via `node_to_comm`, and this id\n",
        "  is attached to the main ranking table as `pr_df[\"community\"]`.\n",
        "\n",
        "The summary table `comm_summary` aggregates, for each community:\n",
        "\n",
        "- `n_books` – number of titles in the community.\n",
        "- `total_pagerank` – sum of PageRank scores inside the community.\n",
        "- `top_genre` – majority value of `category_final` in that community\n",
        "  (fallback to `\"Unknown\"` when no label is available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHhcd8ou8U01"
      },
      "outputs": [],
      "source": [
        "from networkx.algorithms.community import louvain_communities\n",
        "\n",
        "communities = louvain_communities(G_lcc, weight=\"weight\", seed=42)\n",
        "print(\"Detected communities:\", len(communities))\n",
        "\n",
        "node_to_comm = {}\n",
        "for cid, comm in enumerate(communities):\n",
        "    for n in comm:\n",
        "        node_to_comm[n] = cid\n",
        "\n",
        "pr_df[\"community\"] = pr_df[\"Title_canon\"].map(node_to_comm)\n",
        "\n",
        "comm_summary = (\n",
        "    pr_df.dropna(subset=[\"community\"])\n",
        "         .groupby(\"community\")\n",
        "         .agg(\n",
        "             n_books=(\"Title_canon\", \"size\"),\n",
        "             total_pagerank=(\"pagerank\", \"sum\"),\n",
        "             top_genre=(\"category_final\",\n",
        "                        lambda x: x.value_counts().idxmax() if len(x.dropna()) else \"Unknown\")\n",
        "         )\n",
        "         .sort_values(\"n_books\", ascending=False)\n",
        ")\n",
        "\n",
        "print(\"\\nTop 10 communities by size:\")\n",
        "print(comm_summary.head(10))\n",
        "\n",
        "top_comm = comm_summary.head(5)\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.bar(top_comm.index.astype(str), top_comm[\"n_books\"])\n",
        "plt.xlabel(\"Community id\")\n",
        "plt.ylabel(\"Number of books\")\n",
        "plt.title(\"Largest communities in the reviewer-overlap graph\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCFHnZqLUXbM"
      },
      "source": [
        "The printout of the top-10 communities by size, together with the bar\n",
        "chart of `n_books` for the five largest communities, shows that:\n",
        "\n",
        "- the largest clusters contain several hundred books each,\n",
        "- most of the biggest communities are dominated by `['Fiction']`,\n",
        "  while others correspond to more specific areas such as\n",
        "  `['Business & Economics']` or `['History']`.\n",
        "\n",
        "This confirms that the reviewer-overlap graph is not random: books tend\n",
        "to cluster into genre-coherent communities, and PageRank mass is\n",
        "concentrated in a few large, thematically meaningful groups."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtsCn8HF8cWo"
      },
      "source": [
        "### 13. Temporal PageRank"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temporal PageRank extends the baseline PageRank computation by giving **more weight to recent reviews**.  \n",
        "This allows the ranking to respond to *current* user activity rather than treating all reviews (2000–2018) as equally informative.\n",
        "\n",
        "The key idea:\n",
        "\n",
        "> Books with **recent review activity** should receive more teleportation mass, while books with only old reviews should contribute less to current influence.\n",
        "\n",
        "This is done through **personalised PageRank** using a recency-weighted teleportation vector."
      ],
      "metadata": {
        "id": "S8Y_cr1yXn3z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvVZrszs8fZR"
      },
      "source": [
        "#### 13.1 Recency scores and temporal teleportation vector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The canonical interaction table `df_core` contains UNIX timestamps (`review/time`). These are converted to dates and transformed into **review ages** relative to the most recent review.\n",
        "\n",
        "Recency decay is modelled with an exponential kernel:\n",
        "$$\n",
        "w = e^{-\\lambda \\cdot \\text{age (years)}}\n",
        "$$ with $$(\\lambda = 0.7)$$.  \n",
        "Thus, reviews older than ~5–7 years receive much smaller weights, while recent reviews obtain much larger ones.\n",
        "\n",
        "For each book:\n",
        "\n",
        "- review-level recency weights are averaged → `title_recency[t]`,  \n",
        "- the vector is normalised → becomes the **personalization vector** for PageRank.\n",
        "\n",
        "This modifies the PageRank behaviour:\n",
        "\n",
        "- **α = 0.85** — probability of following edges weighted by shared reviewers,  \n",
        "- **1 − α = 0.15** — teleportation step **biased by recency** instead of uniform jumping.\n",
        "\n",
        "The output `pagerank_temporal` provides a **recency-aware influence measure**.\n",
        "\n",
        "Rank shift is defined as:\n",
        "\n",
        "$$\n",
        "\\text{shift}_{\\text{temp vs base}} = \\text{rank}_{\\text{pr}} - \\text{rank}_{\\text{temp}}\n",
        "$$\n",
        "\n",
        "\n",
        "where positive values indicate a book that becomes *more* central under temporal weighting.\n"
      ],
      "metadata": {
        "id": "SHQvuOPvXy1J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_piYO-V8iS2"
      },
      "outputs": [],
      "source": [
        "df_time = df_core[[\"Title_canon\", \"review/time\"]].copy()\n",
        "\n",
        "try:\n",
        "    df_time[\"review_date\"] = pd.to_datetime(df_time[\"review/time\"], unit=\"s\", errors=\"coerce\")\n",
        "except TypeError:\n",
        "    df_time[\"review_date\"] = pd.to_datetime(df_time[\"review/time\"], errors=\"coerce\")\n",
        "\n",
        "df_time = df_time.dropna(subset=[\"review_date\"])\n",
        "\n",
        "max_date = df_time[\"review_date\"].max()\n",
        "age_days = (max_date - df_time[\"review_date\"]).dt.days\n",
        "age_years = age_days / 365.25\n",
        "\n",
        "lambda_decay = 0.7\n",
        "df_time[\"recency_weight\"] = np.exp(-lambda_decay * age_years)\n",
        "\n",
        "title_recency = df_time.groupby(\"Title_canon\")[\"recency_weight\"].mean()\n",
        "print(\"Titles with recency scores:\", title_recency.shape[0])\n",
        "\n",
        "teleport = {}\n",
        "total_mass = 0.0\n",
        "for n in G_lcc.nodes():\n",
        "    w = float(title_recency.get(n, 0.0))\n",
        "    teleport[n] = w\n",
        "    total_mass += w\n",
        "\n",
        "if total_mass == 0.0:\n",
        "    raise ValueError(\"All temporal weights are zero – check review/time parsing.\")\n",
        "\n",
        "teleport = {n: w / total_mass for n, w in teleport.items()}\n",
        "\n",
        "pagerank_temp = nx.pagerank(\n",
        "    G_lcc,\n",
        "    alpha=0.85,\n",
        "    weight=\"weight\",\n",
        "    personalization=teleport\n",
        ")\n",
        "\n",
        "pr_df[\"pagerank_temporal\"] = pr_df[\"Title_canon\"].map(pagerank_temp)\n",
        "pr_df[\"rank_temp\"] = (\n",
        "    pr_df[\"pagerank_temporal\"]\n",
        "      .rank(ascending=False, method=\"min\")\n",
        "      .astype(\"Int64\")\n",
        ")\n",
        "\n",
        "mask_temp = pr_df[\"rank_temp\"].notna()\n",
        "pr_df.loc[mask_temp, \"shift_temp_vs_base\"] = (\n",
        "    pr_df.loc[mask_temp, \"rank_pr\"] - pr_df.loc[mask_temp, \"rank_temp\"]\n",
        ")\n",
        "\n",
        "print(\"Non-null temporal PageRank:\", pr_df[\"pagerank_temporal\"].notna().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this run:\n",
        "\n",
        "* recency scores are available for **16 160** canonical titles;\n",
        "* temporal PageRank is non-null for **8 687** books, matching the LCC.\n",
        "\n",
        "This confirms that temporal PageRank is defined on the same structural core as the\n",
        "baseline ranking, but now biased towards books with recent review activity."
      ],
      "metadata": {
        "id": "fps9x-LMBW-M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpfJQFpv8iF4"
      },
      "source": [
        "#### 13.2 Rank shifts: recent hits vs classics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After computing temporal PageRank using a recency-weighted personalization vector, the analysis examines how book rankings change relative to the baseline (static) PageRank.\n",
        "\n",
        "For clarity, the focus is placed on the top-20 books ranked by baseline PageRank, tracking how their positions shift once temporal weighting is introduced.\n",
        "\n",
        "Each line in the figure connects:\n",
        "\n",
        "* the baseline PageRank rank, and\n",
        "\n",
        "* the corresponding temporal PageRank rank."
      ],
      "metadata": {
        "id": "qMlPT30zZVuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rank-shift visualization (baseline → temporal)\n",
        "N = 20\n",
        "topN = (\n",
        "    pr_df[mask_temp]\n",
        "    .sort_values(\"rank_pr\")\n",
        "    .head(N)\n",
        "    .copy()\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "for _, row in topN.iterrows():\n",
        "    plt.plot(\n",
        "        [0, 1],\n",
        "        [row[\"rank_pr\"], row[\"rank_temp\"]],\n",
        "        marker=\"o\",\n",
        "        linewidth=1\n",
        "    )\n",
        "\n",
        "plt.xticks([0, 1], [\"Baseline PageRank\", \"Temporal PageRank\"])\n",
        "plt.ylabel(\"Rank (lower is better)\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(\"Rank shifts under Temporal PageRank (Top-20 by baseline)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "33osE4TfYTUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Upward movement (better rank under temporal PageRank) indicates books that benefit from recent review activity (recent hits).\n",
        "\n",
        "* Downward movement indicates books whose influence is primarily driven by older reviews (structural classics).\n",
        "\n",
        "This visualization replaces explicit top-gainer and top-loser tables and provides a compact diagnostic of temporal effects.\n",
        "It highlights how temporal PageRank distinguishes current momentum from long-term structural importance, which is not visible in the static ranking alone."
      ],
      "metadata": {
        "id": "KJj3NKukof4v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKfUFnBz8u-n"
      },
      "source": [
        "### 14. PageRank subgraph visualisation (Top-20 titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXdqUagm81Gi"
      },
      "source": [
        "#### 14.1 Build Top-20 PageRank subgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block restricts the analysis to the **20 books with highest PageRank** in `pr_df`:\n",
        "\n",
        "* `top20_titles` – list of the 20 titles with largest `pagerank`;\n",
        "* `G_top20` – induced subgraph of `G_lcc` on those 20 nodes;\n",
        "* `G_core20` – largest connected component inside `G_top20`.\n",
        "\n",
        "Working on `G_core20` avoids drawing isolated nodes: the visualisation focuses on the **main local cluster** formed by the top-20 books in the reviewer-overlap graph."
      ],
      "metadata": {
        "id": "3uaya3vycQzh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AL_bEpw71y5"
      },
      "outputs": [],
      "source": [
        "top20_titles = (\n",
        "    pr_df.sort_values(\"pagerank\", ascending=False)\n",
        "         .head(20)[\"Title_canon\"]\n",
        "         .tolist()\n",
        ")\n",
        "\n",
        "# Induced subgraph on G_lcc (only top-20 nodes).\n",
        "G_top20 = G_lcc.subgraph(top20_titles).copy()\n",
        "\n",
        "# Keep only the largest connected component inside top-20.\n",
        "if G_top20.number_of_edges() > 0:\n",
        "    core_nodes = max(nx.connected_components(G_top20), key=len)\n",
        "    G_core20 = G_top20.subgraph(core_nodes).copy()\n",
        "else:\n",
        "    G_core20 = G_top20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYPABuFF784y"
      },
      "source": [
        "#### 14.2 Draw Top-20 PageRank core"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The subgraph `G_core20` is rendered with a force-directed layout:\n",
        "\n",
        "* node size ∝ normalised PageRank within `G_core20` (`norm_pr`);\n",
        "* node colour ∝ the same normalised PageRank\n",
        "  (colourbar shows **relative influence** inside the top-20 set);\n",
        "* edge width ∝ `weight` (number of shared reviewers)."
      ],
      "metadata": {
        "id": "074Gllx9cfyZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45ltLLvx7_S9"
      },
      "outputs": [],
      "source": [
        "if G_core20.number_of_nodes() > 0:\n",
        "    # Normalise PageRank within this subgraph for size/colour.\n",
        "    pr_top20 = pr_df.set_index(\"Title_canon\").loc[list(G_core20.nodes()), \"pagerank\"]\n",
        "    pr_min, pr_max = pr_top20.min(), pr_top20.max()\n",
        "    norm_pr = {\n",
        "        t: (pr_top20[t] - pr_min) / (pr_max - pr_min + 1e-12)\n",
        "        for t in G_core20.nodes()\n",
        "    }\n",
        "\n",
        "    pos = nx.spring_layout(G_core20, k=0.8, seed=42)\n",
        "\n",
        "    node_sizes = [300 + 2200 * norm_pr[n] for n in G_core20.nodes()]\n",
        "    node_colors = [norm_pr[n] for n in G_core20.nodes()]\n",
        "\n",
        "    edges = list(G_core20.edges(data=True))\n",
        "    edge_weights = [d[\"weight\"] for _, _, d in edges]\n",
        "    max_w = max(edge_weights) if edge_weights else 1\n",
        "    edge_widths = [0.5 + 2.5 * (w / max_w) for w in edge_weights]\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    nodes = nx.draw_networkx_nodes(\n",
        "        G_core20, pos,\n",
        "        node_size=node_sizes,\n",
        "        node_color=node_colors,\n",
        "        cmap=\"viridis\",\n",
        "        alpha=0.9,\n",
        "    )\n",
        "    nx.draw_networkx_edges(\n",
        "        G_core20, pos,\n",
        "        width=edge_widths,\n",
        "        edge_color=\"lightgray\",\n",
        "        alpha=0.6,\n",
        "    )\n",
        "\n",
        "    # Shorten long labels for readability.\n",
        "    labels = {\n",
        "        n: (n[:25] + \"…\") if len(n) > 25 else n\n",
        "        for n in G_core20.nodes()\n",
        "    }\n",
        "    nx.draw_networkx_labels(G_core20, pos, labels=labels, font_size=8)\n",
        "\n",
        "    cbar = plt.colorbar(nodes)\n",
        "    cbar.set_label(\"Normalised PageRank (top-20)\")\n",
        "\n",
        "    plt.title(\"Top-20 PageRank titles: local co-review structure\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Top-20 PageRank titles have no edges between them in the LCC.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Node colour and size both reflect normalised PageRank  (yellow/large = highest influence; purple/small = lowest).  \n",
        "\n",
        "* **High-PageRank hubs** (large, bright nodes such as *City of Bones* and *1st to Die*) act as central aggregators in the co-review network, receiving many weighted paths.\n",
        "* Surrounding them is a **ring of medium-rank nodes** that function as secondary authorities: they connect to the hubs but do not strongly interconnect with each other.\n",
        "* A **local tightly connected cluster** (e.g., the Sharpe titles) forms a small **community / local authority group**, with strong internal reinforcement but weaker connections to the global hub.\n",
        "* Several **peripheral nodes** (small, dark nodes) have low PageRank and contribute little to global influence; they rely on a few weak links to the main structure.\n",
        "\n",
        "Overall, the plot highlights how influence concentrates around a few hub titles, while most books play peripheral or community-specific roles."
      ],
      "metadata": {
        "id": "8prtZZeSClJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Summary — Link Analysis of the Amazon Books Co-Review Graph\n",
        "\n",
        "Using the Amazon Books Reviews dataset, the co-review network reveals several\n",
        "consistent patterns about how readers navigate the catalogue.\n",
        "\n",
        "**1. PageRank identifies structurally central titles, not necessarily the most popular ones.**  \n",
        "PageRank and review count correlate only weakly: many books with modest popularity\n",
        "become influential because they sit at intersections of different reader groups.\n",
        "These titles act as *connectors* in the catalogue, driving traffic between genres.\n",
        "\n",
        "**2. Degree, closeness and betweenness highlight different dimensions of influence.**  \n",
        "High-degree books attract broad attention, while high-closeness titles are positioned\n",
        "to reach the rest of the graph quickly. Betweenness isolates “bridge” books that link\n",
        "otherwise separate reading niches. These measures confirm that influence on Amazon is\n",
        "multi-dimensional and cannot be reduced to volume of reviews alone.\n",
        "\n",
        "**3. The reviewer-overlap graph exhibits clear community structure.**  \n",
        "Louvain clustering finds large, coherent genre communities (e.g. Fiction clusters,\n",
        "Business & Economics, History). PageRank mass is unevenly distributed across them:\n",
        "broad-appeal fiction clusters accumulate the largest share, while specialised\n",
        "communities remain internal but cohesive. This reflects how readers group around\n",
        "stable genre ecosystems.\n",
        "\n",
        "**4. Temporal PageRank captures short-term momentum.**  \n",
        "When recent reviews are weighted more heavily, a subset of titles moves sharply up\n",
        "the ranking. These books show strong *current* engagement even if historically\n",
        "less central. Conversely, long-standing classics lose rank when time is considered:\n",
        "their influence relies on older review activity. This separation between *timeless*\n",
        "and *trending* titles is not visible in standard PageRank.\n",
        "\n",
        "**5. The top-20 subgraph confirms a hub-and-periphery structure.**  \n",
        "Within the most influential titles, a few dominant hubs anchor the network, while\n",
        "smaller clusters form niche authority groups. Peripheral books enter the top-20 only\n",
        "through strong ties to a hub, not through broad connectivity. Visual inspection\n",
        "matches the quantitative patterns seen in degree and PageRank.\n",
        "\n",
        "**Overall takeaway:**  \n",
        "Link analysis provides a richer view of catalogue influence than ratings or\n",
        "popularity alone. It exposes how books function within reader ecosystems, identifies\n",
        "bridges between genres, separates long-term central titles from short-term hits, and\n",
        "reveals how a relatively small portion of books shapes global navigation behaviour\n",
        "on Amazon’s platform.\n"
      ],
      "metadata": {
        "id": "C8AH2Y0nIOjT"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVudAD6RWGPVgB3lmiiPU6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}